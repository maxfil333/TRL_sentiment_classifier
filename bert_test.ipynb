{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418948ad-8036-439c-844e-3fe735acbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from trl import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39573867-1d25-4fc2-879a-4f0309014d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обрезать отзыв до размера n\n",
    "def cut_review(example):\n",
    "    example[\"review\"] = example[\"review\"][0:5000]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157c0420-de8b-48f3-b445-f8c1eaa42695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'sentiment'],\n",
       "    num_rows: 24872\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('imdb', split='test')\n",
    "ds = ds.rename_columns({'text': 'review', 'label': 'sentiment'})\n",
    "ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False)\n",
    "# ds = ds.map(cut_review, batched=False)\n",
    "ds = ds.shuffle(seed=1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be08421e-dc17-4914-acfa-e3519f92cdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': Value(dtype='string', id=None),\n",
       " 'sentiment': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7150ef6-3712-4033-9563-c8d536b16ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wretched. Talk about botched. BEYOND THE POSEIDON ADVENTURE is bad in every respect. Salvagers Michael Caine and Karl Malden decide to tow the wreck of the eponymous ocean liner with a really creaky tug boat. They're challenged by ruthless Telly Savalas and his gang of machine-gun toting goons. This part sequel, part remake has Caine, Malden and ANOTHER group of Poseidon survivors making a similarly dangerous trek out of the sinking ship. Among this group are Shirley Jones, Slim Pickens, Peter Boyle, Shirley Knight and Slim Pickens. Jack Warden plays a blind man. Surely, you'll wish you were blind after seeing this mess. Sally Field is particularly annoying as a stowaway on board Caine's tug.<br /><br />Disaster master Irwin Allen not only produced this one, he decided to direct it as well.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d555c5-d42f-4da8-8b1d-18bfcb29e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_examples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446576f7-d964-449f-b250-af8486ae0c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 16\n",
    "n_test_examples = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ee24a4-3a91-4c62-9238-b3c3325b5772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor(ds['sentiment'][:n_test_examples]).to(device)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d381f2-e055-431c-8838-2c3cadb50528",
   "metadata": {},
   "source": [
    "### DistilBertForSequenceClassification + distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e04c2b-64a8-4a7d-b9fa-b99d1d9a408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "classifier_2 = DistilBertForSequenceClassification.from_pretrained(checkpoint).to(device)\n",
    "tokenizer_2 = DistilBertTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8349e44c-2843-496f-afd4-e1c6981b8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2 = tokenizer_2(ds['review'][0:n_test_examples], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "dataset_2 = TensorDataset(inputs_2['input_ids'], inputs_2['attention_mask'], labels)\n",
    "dataloader_2 = DataLoader(dataset_2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac420f3-91b6-4c10-9c26-c1b9e1fa86a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8222, -3.2315],\n",
       "        [-2.9453,  3.0676],\n",
       "        [-3.7527,  3.9749],\n",
       "        [-3.5014,  3.6809],\n",
       "        [ 1.0436, -0.7575]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: total: 3.05 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    logits_2 = []\n",
    "    labels = []\n",
    "    for batch in dataloader_2:\n",
    "        batch_inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
    "        logits = classifier_2(**batch_inputs).logits\n",
    "        logits_2.append(logits)\n",
    "        labels.append(batch[2])\n",
    "        \n",
    "logits_2 = torch.cat(logits_2, dim=0).to('cpu')\n",
    "labels = torch.cat(labels).to('cpu')\n",
    "\n",
    "display(logits_2[0:5])\n",
    "print()\n",
    "display(labels[0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b3c9bc-b1be-477c-bfd2-57528b2e280a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id_2 = logits_2.argmax(dim=1)\n",
    "predicted_class_id_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5747799c-7bad-4de1-9ed5-ef98c6594283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(ds['sentiment'][0:n_test_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca7dcae4-8a0c-45b9-9fdc-e36f2f58a15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_class_id_2 == labels).sum().item() / len(predicted_class_id_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689d5ce-0e55-4180-bfd4-783ede4a0559",
   "metadata": {},
   "source": [
    "### DistilBertForSequenceClassification + distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "207c2fe8-0f15-4193-99a0-babbf85cf971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "classifier_3 = DistilBertForSequenceClassification.from_pretrained(checkpoint)\n",
    "tokenizer_3 = DistilBertTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "348b38a5-8a0c-4626-88f1-79020fcde4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 23277, 29574,  ...,     0,     0,     0],\n",
       "        [  101,  6874,  9443,  ...,     0,     0,     0],\n",
       "        [  101,  1996,  2200,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2065, 17551,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  3185,  ...,     0,     0,     0],\n",
       "        [  101,  1999,  1996,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_3 = tokenizer_3(ds['review'][0:n_test_examples], padding=True, truncation=True, return_tensors='pt')\n",
    "inputs_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d10a4c14-025d-4619-a1cc-04633836f2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 44s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    logits_3 = classifier_3(**inputs_3).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e711a0-a0e0-4323-938c-2330612fd181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id_3 = logits_3.argmax(dim=1)\n",
    "predicted_class_id_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "932ba59f-7599-40c7-b8c1-480067639428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_class_id_3 == torch.tensor(ds['sentiment'][0:n_test_examples])).sum().item() / len(predicted_class_id_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1322c-2fe7-4ce4-890c-248d6adc2dab",
   "metadata": {},
   "source": [
    "### AutoModelForSequenceClassification + kurianbenoy/distilbert-base-uncased-finetuned-imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8713a957-4482-4059-a66e-3b3ec5c690c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "checkpoint = 'kurianbenoy/distilbert-base-uncased-finetuned-imdb'\n",
    "classifier_4 = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "tokenizer_4 = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fd9b250-b3ca-463e-93b3-3d842f411e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 23277, 29574,  ...,     0,     0,     0],\n",
       "        [  101,  6874,  9443,  ...,     0,     0,     0],\n",
       "        [  101,  1996,  2200,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2065, 17551,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  3185,  ...,     0,     0,     0],\n",
       "        [  101,  1999,  1996,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_4 = tokenizer_4(ds['review'][0:n_test_examples], padding=True, truncation=True, return_tensors='pt')\n",
    "inputs_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d93b5ac-8236-46fe-9dd5-68b3f28677bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 44s\n",
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    logits_4 = classifier_4(**inputs_4).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3b55e56-e4cf-4267-a930-8655e582b307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id_4 = logits_4.argmax(dim=1)\n",
    "predicted_class_id_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2dc893-d554-47cf-8f7d-8af20b8b48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_class_id_4 == torch.tensor(ds['sentiment'][0:n_test_examples])).sum().item() / len(predicted_class_id_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
